---
title: "Predict phylogeny parameters with DNN and Summary statistics"
output: html_document
knitr: opts_knit$set(root.dir = "../")
editor_options: 
  chunk_output_type: console
---

Before running this you should have 
generated your phylogenies (`01_generate-phylogeny.Rmd`)
and computed their summary statistics (`02_convert-phylogeny.Rmd`).

## Set up

```{r setup, include=FALSE}
knitr::opts_knit$set(root.dir = "../")
model <- "musse"
expname <- "30_4-honest"
```

Data preparation: here we just need to scale the summary statistics,
before giving them to the DNN,
so that they are all put on an equal footing. 

```{r}
source("R/phylo-inference-ml.R")
set.seed(113)
sumstat <- readRDS(paste("data/phylogeny-", model, "-", expname, "-sumstat.rds", sep=""))
true <- readRDS(paste("data/true-parameters-", model, "-", expname, ".rds", sep=""))
n_taxa <- c(100, 1000) # range of phylogeny size
sumstat <- scale_summary_statistics(sumstat, c(100,1000), names(true))
device = "gpu" # change if you want to compute GPUs
```


## Create datasets

Define the of the training, validation and test sets. 

```{r}
# Define size of datasets in percentage of the total number of phylogenies.
total_number_phylogenies <- nrow(sumstat)
n_train    <- 0.7 * total_number_phylogenies
n_valid    <- 0.2 * total_number_phylogenies
n_test     <- 0.1 * total_number_phylogenies
batch_size <- 128

# 

# Pick the phylogenies randomly.
ds <- convert_ss_dataframe_to_dataset(sumstat)
train_indices <- sample(1:nrow(sumstat), n_train)
not_train_indices <- setdiff(1:nrow(sumstat), train_indices)
valid_indices <- sample(not_train_indices, n_valid)
test_indices  <- setdiff(not_train_indices, valid_indices)

# Create the datasets.
train_ds <- ds(sumstat[train_indices, ], names(true), c())
valid_ds <- ds(sumstat[valid_indices, ], names(true), c())
test_ds  <- ds(sumstat[test_indices, ], names(true), c())

# Create the dataloader.
train_dl <- train_ds %>% dataloader(batch_size=batch_size, shuffle=TRUE)
valid_dl <- valid_ds %>% dataloader(batch_size=batch_size, shuffle=FALSE)
test_dl  <- test_ds  %>% dataloader(batch_size=1, shuffle=FALSE)
```

## Build the neural network 

```{r}
# Specify neural network parameters. 
n_in      <- length(train_ds[1]$x) # number of neurons of the input layer 
n_out     <- length(true)
n_hidden  <- 1000 # number of neurons in the hidden layers 
p_dropout <- 0.2 # dropout probability 
n_epochs  <- 1000 # maximum number of epochs for the training 
patience  <- 10 # patience of the early stopping 

# Build the neural network.
dnn.net <- nn_module(
  
  "ss-dnn", 
  
  initialize = function(){
    self$fc1 <- nn_linear(in_features = n_in, out_features = n_hidden)
    self$fc2 <- nn_linear(in_features = n_hidden, out_features = n_hidden)
    self$fc3 <- nn_linear(in_features = n_hidden, out_features = n_hidden)
    self$fc4 <- nn_linear(in_features = n_hidden, out_features = n_hidden)
    self$fc5 <- nn_linear(in_features = n_hidden, out_features = n_out)
  }, 
  
  forward = function(x){
    x %>%
      self$fc1() %>%
      nnf_relu() %>%
      nnf_dropout(p = p_dropout) %>%
      
      self$fc2() %>%
      nnf_relu() %>%
      nnf_dropout(p = p_dropout) %>%
      
      self$fc3() %>%
      nnf_relu() %>%
      nnf_dropout(p = p_dropout) %>%
      
      self$fc4() %>%
      nnf_relu() %>%
      nnf_dropout(p = p_dropout) %>%
      
      self$fc5()
  }
)

# Set up the neural network.
dnn <- dnn.net() # create CNN
dnn$to(device = device) # Move it to the chosen GPU
opt <- optim_adam(params = dnn$parameters) # optimizer 
```

## Training 

```{r}
train_batch <- function(b){
  opt$zero_grad()
  output <- dnn(b$x$to(device = device))
  target <- b$y$to(device = device)
  loss <- nnf_mse_loss(output, target)
  loss$backward()
  opt$step()
  loss$item()
}

valid_batch <- function(b) {
  output <- dnn(b$x$to(device = device))
  target <- b$y$to(device = device)
  loss <- nnf_mse_loss(output, target)
  loss$item()
}
```

```{r}
# Initialize parameters for the training loop.
epoch     <- 1
trigger   <- 0 
last_loss <- 100


# Training loop.
while (epoch < n_epochs & trigger < patience) {
  
  # Training 
  dnn$train()
  train_loss <- c()
  coro::loop(for (b in train_dl) { # loop over batches 
    loss <- train_batch(b)
    train_loss <- c(train_loss, loss)
  })
  
  # Print Epoch and value of Loss function 
  cat(sprintf("epoch %0.3d/%0.3d - train - loss: %3.5f \n",
              epoch, n_epochs, mean(train_loss)))
  
  # Validation 
  dnn$eval()
  valid_loss <- c()
  coro::loop(for (b in test_dl) { # loop over batches 
    loss <- valid_batch(b)
    valid_loss <- c(valid_loss, loss)
  })
  current_loss <- mean(valid_loss)
  
  # Early Stopping 
  if (current_loss > last_loss){trigger <- trigger + 1} 
  else{
    trigger   <- 0
    last_loss <- current_loss
  }
  
  # Print Epoch and value of Loss function
  cat(sprintf("epoch %0.3d/%0.3d - valid - loss: %3.5f \n",
              epoch, n_epochs, current_loss))
  
  epoch <- epoch + 1

}
```

## Evaluation 

Compute predicted parameters on test set.

```{r}
dnn$eval()
pred <- vector(mode = "list", length = n_out)
names(pred) <- names(true)

# Compute predictions 
coro::loop(for (b in test_dl) {
  out <- dnn(b$x$to(device = device))
  p <- as.numeric(out$to(device = "gpu")) # move the tensor to CPU 
  for (i in 1:n_out){pred[[i]] <- c(pred[[i]], p[i])}
})
```

Now that you have the predicted parameters you can, for instance, 
plot the predicted value by the neural network vs. the true values.

```{r}
par(mfrow=c(1,2))
plot(true[[1]][test_indices], pred[[1]], xlab="True", ylab="Predicted", title="lambda1")
abline(0, 1)
plot(true[[2]][test_indices], pred[[2]], xlab="True", ylab="Predicted", title="lambda2")
abline(0, 1)


# musse model
if (model == "musse")
{ par(mfrow=c(4, 3))
  for (i in 1:12){
    plot(true[[i]][test_indices], pred[[i]], xlab="True", ylab="Predicted", main=names(true)[i])
    abline(0, 1)
  }}

# geosse model (7 parameters)
else if (model == "geosse")
{ par(mfrow=c(4, 2))
  for (i in 1:7){
    plot(true[[i]][test_indices], pred[[i]], xlab="True", ylab="Predicted", main=names(true)[i])
    abline(0, 1)
  }}

# bisse model (5 parameters)
else if (model == "bisse")
{ par(mfrow=c(3, 2))
  for (i in 1:5){
    plot(true[[i]][test_indices], pred[[i]], xlab="True", ylab="Predicted", main=names(true)[i])
    abline(0, 1)
  }}

# bisseness model (10 parameters)
else if (model == "bisseness")
{ par(mfrow=c(5, 2))
  for (i in 1:10){
    plot(true[[i]][test_indices], pred[[i]], xlab="True", ylab="Predicted", main=names(true)[i])
    abline(0, 1)
    # plot trend line
    abline(lm(pred[[i]] ~ true[[i]][test_indices]), col="red")
  }}

# musse4 model (20 parameters)
else if (model == "musse4")
{ par(mfrow=c(5, 4))
  for (i in 1:20){
    plot(true[[i]][test_indices], pred[[i]], xlab="True", ylab="Predicted", main=names(true)[i])
    abline(0, 1)
  }}

# classe model (10 parameters)
else if (model == "classe")
{ par(mfrow=c(5, 2))
  for (i in 1:10){
    plot(true[[i]][test_indices], pred[[i]], xlab="True", ylab="Predicted", main=names(true)[i])
    abline(0, 1)
  }}

# bd model (2 parameters)
else if (model == "bd")
{ par(mfrow=c(1, 2))
  for (i in 1:2){
    plot(true[[i]][test_indices], pred[[i]], xlab="True", ylab="Predicted", main=names(true)[i])
    abline(0, 1)
  }}
```

Relative error: (lambda_true-lambda_predicted) / lambda_true

```{r}
# relative error: (lambda_true-lambda_predicted) / lambda_true
if (model == "musse")
{ par(mfrow=c(4, 3))
  for (i in 1:12){
    plot(true[[i]][test_indices], (true[[i]][test_indices] - pred[[i]]) / true[[i]][test_indices], xlab="True", ylab="Relative error", main=names(true)[i])
    abline(0, 0)
  }}

# geosse model (7 parameters)
else if (model == "geosse")
{ par(mfrow=c(4, 2))
  for (i in 1:7){
    plot(true[[i]][test_indices], (true[[i]][test_indices] - pred[[i]]) / true[[i]][test_indices], xlab="True", ylab="Relative error", main=names(true)[i])
    abline(0, 0)
  }}

# bisse model (5 parameters)
else if (model == "bisse")
{ par(mfrow=c(3, 2))
  for (i in 1:5){
    plot(true[[i]][test_indices], (true[[i]][test_indices] - pred[[i]]) / true[[i]][test_indices], xlab="True", ylab="Relative error", main=names(true)[i])
    abline(0, 0)
  }}

# bisseness model (10 parameters)
else if (model == "bisseness")
{ par(mfrow=c(5, 2))
  for (i in 1:10){
    plot(true[[i]][test_indices], (true[[i]][test_indices] - pred[[i]]) / true[[i]][test_indices], xlab="True", ylab="Relative error", main=names(true)[i])
    abline(0, 0)
  }}

# musse4 model (20 parameters)
else if (model == "musse4")
{ par(mfrow=c(5, 4))
  for (i in 1:20){
    plot(true[[i]][test_indices], (true[[i]][test_indices] - pred[[i]]) / true[[i]][test_indices], xlab="True", ylab="Relative error", main=names(true)[i])
    abline(0, 0)
  }}

# classe model (10 parameters)
else if (model == "classe")
{ par(mfrow=c(5, 2))
  for (i in 1:10){
    plot(true[[i]][test_indices], (true[[i]][test_indices] - pred[[i]]) / true[[i]][test_indices], xlab="True", ylab="Relative error", main=names(true)[i])
    abline(0, 0)
  }}

# bd model (2 parameters)
else if (model == "bd")
{ par(mfrow=c(1, 2))
  for (i in 1:2){
    plot(true[[i]][test_indices], (true[[i]][test_indices] - pred[[i]]) / true[[i]][test_indices], xlab="True", ylab="Relative error", main=names(true)[i])
    abline(0, 0)
  }}
```

Absolute error: |lambda_true-lambda_predicted|

```{r}
# absolute error: |lambda_true-lambda_predicted|
if (model == "musse")
{ par(mfrow=c(4, 3))
  for (i in 1:12){
    plot(true[[i]][test_indices], abs(true[[i]][test_indices] - pred[[i]]), xlab="True", ylab="Absolute error", main=names(true)[i])
    abline(0, 0)
    abline(h=mean(abs(true[[i]][test_indices] - pred[[i]])), col="red")
    # legend
    legend("topright", legend=c("mean"), col=c("red"), lty=1:1, cex=0.8)
  }}

# bd model (2 parameters)
else if (model == "bd")
{ par(mfrow=c(1, 2))
  for (i in 1:2){
    plot(true[[i]][test_indices], abs(true[[i]][test_indices] - pred[[i]]), xlab="True", ylab="Absolute error", main=names(true)[i])
    abline(0, 0)
    abline(h=mean(abs(true[[i]][test_indices] - pred[[i]])), col="red")
    # legend
    legend("topright", legend=c("mean"), col=c("red"), lty=1:1, cex=0.8)
  }}

# geosse model (7 parameters)
else if (model == "geosse")
{ par(mfrow=c(4, 2))
  for (i in 1:7){
    plot(true[[i]][test_indices], abs(true[[i]][test_indices] - pred[[i]]), xlab="True", ylab="Absolute error", main=names(true)[i])
  }}

# bisse model (5 parameters)
else if (model == "bisse")
{ par(mfrow=c(3, 2))
  for (i in 1:5){
    plot(true[[i]][test_indices], abs(true[[i]][test_indices] - pred[[i]]), xlab="True", ylab="Absolute error", main=names(true)[i])
  }}

# bisseness model (10 parameters)
else if (model == "bisseness")
{ par(mfrow=c(5, 2))
  for (i in 1:10){
    plot(true[[i]][test_indices], abs(true[[i]][test_indices] - pred[[i]]), xlab="True", ylab="Absolute error", main=names(true)[i])
  }}

# musse4 model (20 parameters)
else if (model == "musse4")
{ par(mfrow=c(5, 4))
  for (i in 1:20){
    plot(true[[i]][test_indices], abs(true[[i]][test_indices] - pred[[i]]), xlab="True", ylab="Absolute error", main=names(true)[i])
  }}

# classe model (10 parameters)
else if (model == "classe")
{ par(mfrow=c(5, 2))
  for (i in 1:10){
    plot(true[[i]][test_indices], abs(true[[i]][test_indices] - pred[[i]]), xlab="True", ylab="Absolute error", main=names(true)[i])
  }}
```



```{r}
```